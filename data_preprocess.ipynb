{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVHN Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Preprocessing the 32 x 32 image datset **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing the 32-by-32 images from the SVHN dataset centered around a single digit. In this dataset all digits have been resized to a fixed resolution of 32-by-32 pixels. The original character bounding boxes are extended in the appropriate dimension to become square windows, so that resizing them to 32-by-32 pixels does not introduce aspect ratio distortions\n",
    "\n",
    "In this notebook we apply the following preprocessing steps:\n",
    "\n",
    "\n",
    "   * Create a Startified 13% of data in Validation Set\n",
    "   * Converting the Label 10's to 0's\n",
    "   * Greyscale conversion of image(data) for easy computation\n",
    "   * Normalization of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` Reading the .MAT files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\" Helper function for loading a MAT-File\"\"\"\n",
    "    data = loadmat(path)\n",
    "    return data['X'], data['y']\n",
    "\n",
    "X_train, y_train = load_data('train_32x32.mat')\n",
    "X_test, y_test = load_data('test_32x32.mat')\n",
    "\n",
    "print(\"Training Set\", X_train.shape, y_train.shape)\n",
    "print(\"Test Set\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**` Transposing the the train and test data\n",
    "by converting it from  \n",
    "(width, height, channels, size) -> (size, width, height, channels) `**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the image arrays\n",
    "X_train, y_train = X_train.transpose((3,0,1,2)), y_train[:,0]\n",
    "X_test, y_test = X_test.transpose((3,0,1,2)), y_test[:,0]\n",
    "\n",
    "print(\"Training Set\", X_train.shape)\n",
    "print(\"Test Set\", X_test.shape)\n",
    "print('')\n",
    "\n",
    "# Calculate the total number of images\n",
    "num_images = X_train.shape[0] + X_test.shape[0]\n",
    "\n",
    "print(\"Total Number of Images\", num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "` Plotting Function for fig in n rows X m columns \n",
    "can be used for grayscale and RGB both`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(img, labels, nrows, ncols):\n",
    "    \"\"\" Plot nrows x ncols images\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows, ncols)\n",
    "    for i, ax in enumerate(axes.flat): \n",
    "        if img[i].shape == (32, 32, 3):\n",
    "            ax.imshow(img[i])\n",
    "        else:\n",
    "            ax.imshow(img[i,:,:,0])\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training set images\n",
    "plot_images(X_train, y_train, 2, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of testing set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some test set images\n",
    "plot_images(X_test, y_test, 2, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Distribution of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "\n",
    "fig.suptitle('Class Distribution', fontsize=14, fontweight='bold', y=1.05)\n",
    "\n",
    "ax1.hist(y_train, bins=10)\n",
    "ax1.set_title(\"Training set\")\n",
    "ax1.set_xlim(1, 10)\n",
    "\n",
    "ax2.hist(y_test, color='g', bins=10)\n",
    "ax2.set_title(\"Test set\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All distributions have a positive skew, meaning that we have an underweight of higher values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Label 10 -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 10] = 0\n",
    "y_test[y_test == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Training to Train+Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Splitting to 13% in Val Set as it gives around 9500 data\n",
    "having min. of 800 instances of each class`\n",
    "\n",
    "`Using random state to regenrate the whole Dataset in re-run`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.13, random_state=7, stratify = y_train)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.13, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize New distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "\n",
    "fig.suptitle('Class Distribution', fontsize=14, fontweight='bold', y=1.05)\n",
    "\n",
    "ax1.hist(y_train, bins=10)\n",
    "ax1.set_title(\"Training set\")\n",
    "ax1.set_xlim(1, 10)\n",
    "\n",
    "ax2.hist(y_val, color='g', bins=10)\n",
    "ax2.set_title(\"Validation set\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Data in each Set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Grayscale Conversion \n",
    "\n",
    "To speed up our experiments we will convert our images from RGB to Grayscale, which grately reduces the amount of data we will have to process. \n",
    "\n",
    " ** Y = 0.2990R + 0.5870G + 0.1140B **\n",
    "\n",
    "Here is a simple function that helps us print the size of a numpy array in a human readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(images):\n",
    "    return np.expand_dims(np.dot(images, [0.2990, 0.5870, 0.1140]), axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Converting to Float for numpy computation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_greyscale = rgb2gray(X_train).astype(np.float32)\n",
    "test_greyscale = rgb2gray(X_test).astype(np.float32)\n",
    "val_greyscale = rgb2gray(X_val).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Set\", train_greyscale.shape)\n",
    "print(\"Validation Set\", val_greyscale.shape)\n",
    "print(\"Test Set\", test_greyscale.shape)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` Removing RGB train, test, val set \n",
    "to reduce RAM Storage occupied by them`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the Grayscale Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` Before Normalization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_greyscale, y_train, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "After skimming some of the publications with the lowest error rate on the SVHN dataset, found different pre-processing techniques applied to the SVHN dataset.\n",
    "\n",
    "    Liang et al. 2015 report that the pre-processed the images by removing the per-pixel mean value calculated over \n",
    "    the entire set.\n",
    "    Goodfellow et al. 2013 report that they subtract the mean from every image.\n",
    "\n",
    "Normalization refers to normalizing the data dimensions so that they are of approximately the same scale. \n",
    "Divide each dimension by its standard deviation, once it has been zero-centered. \n",
    "\n",
    "The following figure taken from the [CS231n notes](http://cs231n.github.io/neural-networks-2/) illutrates how this changes the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![normalized_img.png](http://cs231n.github.io/assets/nn2/prepro1.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean on the training data\n",
    "train_mean = np.mean(train_greyscale, axis=0)\n",
    "\n",
    "# Calculate the std on the training data\n",
    "train_std = np.std(train_greyscale, axis=0)\n",
    "\n",
    "# Subtract it equally from all splits\n",
    "train_greyscale_norm = (train_greyscale - train_mean) / train_std\n",
    "test_greyscale_norm = (test_greyscale - train_mean)  / train_std\n",
    "val_greyscale_norm = (val_greyscale - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Plotting After Normalization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(train_greyscale_norm, y_train, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Apply One Hot Encoding to make label\n",
    "suitable for CNN Classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    "# Fit the OneHotEncoder\n",
    "enc = OneHotEncoder().fit(y_train.reshape(-1, 1))\n",
    "\n",
    "# Transform the label values to a one-hot-encoding scheme\n",
    "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "y_val = enc.transform(y_val.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(\"Training set\", y_train.shape)\n",
    "print(\"Validation set\", y_val.shape)\n",
    "print(\"Test set\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Stored only the Grayscale Data \n",
    "not the RGB `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Create file\n",
    "h5f = h5py.File('SVHN_grey.h5', 'w')\n",
    "\n",
    "# Store the datasets\n",
    "h5f.create_dataset('X_train', data=train_greyscale_norm)\n",
    "h5f.create_dataset('y_train', data=y_train)\n",
    "h5f.create_dataset('X_test', data=test_greyscale_norm)\n",
    "h5f.create_dataset('y_test', data=y_test)\n",
    "h5f.create_dataset('X_val', data=val_greyscale_norm)\n",
    "h5f.create_dataset('y_val', data=y_val)\n",
    "\n",
    "# Close the file\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
